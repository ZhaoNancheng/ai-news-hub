# 2026-02-14 AI News æ¯æ—¥ç®€æŠ¥

**æ—¥æœŸ**: 2026-02-14 08:01:25
**æ¥æº**: arXiv CS.AI + cs.LG
**è¦†ç›–èŒƒå›´**: è¿‡å»48å°æ—¶
**è¯­è¨€**: ä¸­è‹±æ–‡æ··åˆ ğŸŒ

---

## ğŸ“° ä»Šæ—¥è¦é—»

å…±æ”¶é›† 15 æ¡æœ€æ–° AI ç ”ç©¶

---

### Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment

**æ¥æº**: arXiv CS.RO
**æ—¶é—´**: 2026-02-12T18:59:59Z
**é“¾æ¥**: [2602.12281v1](https://arxiv.org/abs/2602.12281v1)

**æ‘˜è¦**: The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the "intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that ...

**ä½œè€…**: Jacky Kwok, Xilun Zhang, Mengdi Xu, Yuejiang Liu, Azalia Mirhoseini
**åˆ†ç±»**: cs.RO, cs.AI, eess.SY

---

### UniT: Unified Multimodal Chain-of-Thought Test-time Scaling

**æ¥æº**: arXiv CS.CV
**æ—¶é—´**: 2026-02-12T18:59:49Z
**é“¾æ¥**: [2602.12279v1](https://arxiv.org/abs/2602.12279v1)

**æ‘˜è¦**: Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional i...

**ä½œè€…**: Leon Liangyu Chen, Haoyu Ma, Zhipeng Fan, Ziqi Huang, Animesh Sinha
**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

---

### AttentionRetriever: Attention Layers are Secretly Long Document Retrievers

**æ¥æº**: arXiv CS.IR
**æ—¶é—´**: 2026-02-12T18:59:35Z
**é“¾æ¥**: [2602.12278v1](https://arxiv.org/abs/2602.12278v1)

**æ‘˜è¦**: Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based...

**ä½œè€…**: David Jiahao Fu, Lam Thanh Do, Jiayu Li, Kevin Chen-Chuan Chang
**åˆ†ç±»**: cs.IR, cs.AI

---

### Agentic Test-Time Scaling for WebAgents

**æ¥æº**: arXiv CS.AI
**æ—¶é—´**: 2026-02-12T18:58:30Z
**é“¾æ¥**: [2602.12276v1](https://arxiv.org/abs/2602.12276v1)

**æ‘˜è¦**: Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents. We first conduct an empirical study of inference-...

**ä½œè€…**: Nicholas Lee, Lutfi Eren Erdogan, Chris Joseph John, Surya Krishnapillai, Michael W. Mahoney
**åˆ†ç±»**: cs.AI, cs.CL

---

### On-Policy Context Distillation for Language Models

**æ¥æº**: arXiv CS.CL
**æ—¶é—´**: 2026-02-12T18:58:28Z
**é“¾æ¥**: [2602.12275v1](https://arxiv.org/abs/2602.12275v1)

**æ‘˜è¦**: Context distillation enables language models to internalize in-context knowledge into their parameters. In our work, we propose On-Policy Context Distillation (OPCD), a framework that bridges on-policy distillation with context distillation by training a student model on its own generated trajectories while minimizing reverse Kullback-Leibler divergence against a context-conditioned teacher. We demonstrate the effectiveness of OPCD on two important applications: experiential knowledge distillati...

**ä½œè€…**: Tianzhu Ye, Li Dong, Xun Wu, Shaohan Huang, Furu Wei
**åˆ†ç±»**: cs.CL

---

### Function-Space Decoupled Diffusion for Forward and Inverse Modeling in Carbon Capture and Storage

**æ¥æº**: arXiv CS.LG
**æ—¶é—´**: 2026-02-12T18:58:12Z
**é“¾æ¥**: [2602.12274v1](https://arxiv.org/abs/2602.12274v1)

**æ‘˜è¦**: Accurate characterization of subsurface flow is critical for Carbon Capture and Storage (CCS) but remains challenged by the ill-posed nature of inverse problems with sparse observations. We present Fun-DDPS, a generative framework that combines function-space diffusion models with differentiable neural operator surrogates for both forward and inverse modeling. Our approach learns a prior distribution over geological parameters (geomodel) using a single-channel diffusion model, then leverages a L...

**ä½œè€…**: Xin Ju, Jiachen Yao, Anima Anandkumar, Sally M. Benson, Gege Wen
**åˆ†ç±»**: cs.LG, physics.geo-ph

---

### Learning to Control: The iUzawa-Net for Nonsmooth Optimal Control of Linear PDEs

**æ¥æº**: arXiv MATH.OC
**æ—¶é—´**: 2026-02-12T18:57:43Z
**é“¾æ¥**: [2602.12273v1](https://arxiv.org/abs/2602.12273v1)

**æ‘˜è¦**: We propose an optimization-informed deep neural network approach, named iUzawa-Net, aiming for the first solver that enables real-time solutions for a class of nonsmooth optimal control problems of linear partial differential equations (PDEs). The iUzawa-Net unrolls an inexact Uzawa method for saddle point problems, replacing classical preconditioners and PDE solvers with specifically designed learnable neural networks. We prove universal approximation properties and establish the asymptotic $\v...

**ä½œè€…**: Yongcun Song, Xiaoming Yuan, Hangrui Yue, Tianyou Zeng
**åˆ†ç±»**: math.OC, cs.LG, math.NA

---

### MonarchRT: Efficient Attention for Real-Time Video Generation

**æ¥æº**: arXiv CS.CV
**æ—¶é—´**: 2026-02-12T18:56:53Z
**é“¾æ¥**: [2602.12271v1](https://arxiv.org/abs/2602.12271v1)

**æ‘˜è¦**: Real-time video generation with Diffusion Transformers is bottlenecked by the quadratic cost of 3D self-attention, especially in real-time regimes that are both few-step and autoregressive, where errors compound across time and each denoising step must carry substantially more information. In this setting, we find that prior sparse-attention approximations break down, despite showing strong results for bidirectional, many-step diffusion. Specifically, we observe that video attention is not relia...

**ä½œè€…**: Krish Agarwal, Zhuoming Chen, Cheng Luo, Yongqi Chen, Haizhong Zheng
**åˆ†ç±»**: cs.CV, cs.LG

---

### Creative Ownership in the Age of AI

**æ¥æº**: arXiv ECON.TH
**æ—¶é—´**: 2026-02-12T18:56:42Z
**é“¾æ¥**: [2602.12270v1](https://arxiv.org/abs/2602.12270v1)

**æ‘˜è¦**: Copyright law focuses on whether a new work is "substantially similar" to an existing one, but generative AI can closely imitate style without copying content, a capability now central to ongoing litigation. We argue that existing definitions of infringement are ill-suited to this setting and propose a new criterion: a generative AI output infringes on an existing work if it could not have been generated without that work in its training corpus. To operationalize this definition, we model genera...

**ä½œè€…**: Annie Liang, Jay Lu
**åˆ†ç±»**: econ.TH, cs.AI, cs.GT

---

### CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use

**æ¥æº**: arXiv CS.AI
**æ—¶é—´**: 2026-02-12T18:55:09Z
**é“¾æ¥**: [2602.12268v1](https://arxiv.org/abs/2602.12268v1)

**æ‘˜è¦**: AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2,...

**ä½œè€…**: Zhen Zhang, Kaiqiang Song, Xun Wang, Yebowen Hu, Weixiang Yan
**åˆ†ç±»**: cs.AI

---

### Self-Supervised Learning via Flow-Guided Neural Operator on Time-Series Data

**æ¥æº**: arXiv CS.LG
**æ—¶é—´**: 2026-02-12T18:54:57Z
**é“¾æ¥**: [2602.12267v1](https://arxiv.org/abs/2602.12267v1)

**æ‘˜è¦**: Self-supervised learning (SSL) is a powerful paradigm for learning from unlabeled time-series data. However, popular methods such as masked autoencoders (MAEs) rely on reconstructing inputs from a fixed, predetermined masking ratio. Instead of this static design, we propose treating the corruption level as a new degree of freedom for representation learning, enhancing flexibility and performance. To achieve this, we introduce the Flow-Guided Neural Operator (FGNO), a novel framework combining op...

**ä½œè€…**: Duy Nguyen, Jiachen Yao, Jiayun Wang, Julius Berner, Animashree Anandkumar
**åˆ†ç±»**: cs.LG

---

### T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization

**æ¥æº**: arXiv CS.CL
**æ—¶é—´**: 2026-02-12T18:52:35Z
**é“¾æ¥**: [2602.12262v1](https://arxiv.org/abs/2602.12262v1)

**æ‘˜è¦**: Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories. We...

**ä½œè€…**: Tunyu Zhang, Xinxi Zhang, Ligong Han, Haizhou Shi, Xiaoxiao He
**åˆ†ç±»**: cs.CL, cs.LG

---

### Think like a Scientist: Physics-guided LLM Agent for Equation Discovery

**æ¥æº**: arXiv CS.AI
**æ—¶é—´**: 2026-02-12T18:49:27Z
**é“¾æ¥**: [2602.12259v1](https://arxiv.org/abs/2602.12259v1)

**æ‘˜è¦**: Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries...

**ä½œè€…**: Jianke Yang, Ohm Venkatachalam, Mohammad Kianezhad, Sharvaree Vadgama, Rose Yu
**åˆ†ç±»**: cs.AI, cs.LG

---

### On the implicit regularization of Langevin dynamics with projected noise

**æ¥æº**: arXiv MATH.PR
**æ—¶é—´**: 2026-02-12T18:45:42Z
**é“¾æ¥**: [2602.12257v1](https://arxiv.org/abs/2602.12257v1)

**æ‘˜è¦**: We study Langevin dynamics with noise projected onto the directions orthogonal to an isometric group action. This mathematical model is introduced to shed new light on the effects of symmetry on stochastic gradient descent for over-parametrized models. Our main result identifies a novel form of implicit regularization: when the initial and target density are both invariant under the group action, Langevin dynamics with projected noise is equivalent in law to Langevin dynamics with isotropic diff...

**ä½œè€…**: Govind Menon, Austin J. Stromme, Adrien Vacher
**åˆ†ç±»**: math.PR, cs.AI

---

### Is Online Linear Optimization Sufficient for Strategic Robustness?

**æ¥æº**: arXiv CS.GT
**æ—¶é—´**: 2026-02-12T18:41:55Z
**é“¾æ¥**: [2602.12253v1](https://arxiv.org/abs/2602.12253v1)

**æ‘˜è¦**: We consider bidding in repeated Bayesian first-price auctions. Bidding algorithms that achieve optimal regret have been extensively studied, but their strategic robustness to the seller's manipulation remains relatively underexplored. Bidding algorithms based on no-swap-regret algorithms achieve both desirable properties, but are suboptimal in terms of statistical and computational efficiency. In contrast, online gradient ascent is the only algorithm that achieves $O(\sqrt{TK})$ regret and strat...

**ä½œè€…**: Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng
**åˆ†ç±»**: cs.GT, cs.LG

---


---
**æ›´æ–°æ—¶é—´**: 2026-02-14 08:01:25
**æ•°æ®æ¥æº**: arXiv.org
**ç”±**: è´¾ç»´æ–¯ (JARVIS) è‡ªåŠ¨ç”Ÿæˆ ğŸ¤–
