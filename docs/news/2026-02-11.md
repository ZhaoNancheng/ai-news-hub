# 2026-02-11 AI News æ¯æ—¥ç®€æŠ¥

**æ—¥æœŸ**: 2026-02-11 09:50:20
**æ¥æº**: arXiv CS.AI
**è¦†ç›–èŒƒå›´**: è¿‡å»48å°æ—¶
**è¯­è¨€**: ä¸­è‹±æ–‡æ··åˆ ğŸŒ

---

## ğŸ“° ä»Šæ—¥è¦é—»

å…±æ”¶é›† 10 æ¡æœ€æ–°æ–°é—»

---

### LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation

**æ¥æº**: arXiv CS.AI  
**æ—¶é—´**: Tue, 10 Feb 2026 00:00:00 -0500  
**é“¾æ¥**: https://arxiv.org/abs/2602.07032

**æ‘˜è¦**: arXiv:2602.07032v1 Announce Type: new 
Abstract: Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machi...

---
### ST-Raptor: An Agentic System for Semi-Structured Table QA

**æ¥æº**: arXiv CS.AI  
**æ—¶é—´**: Tue, 10 Feb 2026 00:00:00 -0500  
**é“¾æ¥**: https://arxiv.org/abs/2602.07034

**æ‘˜è¦**: arXiv:2602.07034v1 Announce Type: new 
Abstract: Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations...

---
### DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents

**æ¥æº**: arXiv CS.AI  
**æ—¶é—´**: Tue, 10 Feb 2026 00:00:00 -0500  
**é“¾æ¥**: https://arxiv.org/abs/2602.07035

**æ‘˜è¦**: arXiv:2602.07035v1 Announce Type: new 
Abstract: Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, thei...

---
### Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods

**æ¥æº**: arXiv CS.AI  
**æ—¶é—´**: Tue, 10 Feb 2026 00:00:00 -0500  
**é“¾æ¥**: https://arxiv.org/abs/2602.07040

**æ‘˜è¦**: arXiv:2602.07040v1 Announce Type: new 
Abstract: We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improv...

---
### Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?

**æ¥æº**: arXiv CS.AI  
**æ—¶é—´**: Tue, 10 Feb 2026 00:00:00 -0500  
**é“¾æ¥**: https://arxiv.org/abs/2602.07055

**æ‘˜è¦**: arXiv:2602.07055v1 Announce Type: new 
Abstract: Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We prop...

---
### ANCHOR: Branch-Point Data Generation for GUI Agents

**æ¥æº**: arXiv CS.AI  
**æ—¶é—´**: Tue, 10 Feb 2026 00:00:00 -0500  
**é“¾æ¥**: https://arxiv.org/abs/2602.07153

**æ‘˜è¦**: arXiv:2602.07153v1 Announce Type: new 
Abstract: End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drift...

---
### PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents

**æ¥æº**: arXiv CS.AI  
**æ—¶é—´**: Tue, 10 Feb 2026 00:00:00 -0500  
**é“¾æ¥**: https://arxiv.org/abs/2602.07187

**æ‘˜è¦**: arXiv:2602.07187v1 Announce Type: new 
Abstract: Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe ...

---
### Is there "Secret Sauce'' in Large Language Model Development?

**æ¥æº**: arXiv CS.AI  
**æ—¶é—´**: Tue, 10 Feb 2026 00:00:00 -0500  
**é“¾æ¥**: https://arxiv.org/abs/2602.07238

**æ‘˜è¦**: arXiv:2602.07238v1 Announce Type: new 
Abstract: Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-dat...

---
### From Out-of-Distribution Detection to Hallucination Detection: A Geometric View

**æ¥æº**: arXiv CS.AI  
**æ—¶é—´**: Tue, 10 Feb 2026 00:00:00 -0500  
**é“¾æ¥**: https://arxiv.org/abs/2602.07253

**æ‘˜è¦**: arXiv:2602.07253v1 Announce Type: new 
Abstract: Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain l...

---
### Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective

**æ¥æº**: arXiv CS.AI  
**æ—¶é—´**: Tue, 10 Feb 2026 00:00:00 -0500  
**é“¾æ¥**: https://arxiv.org/abs/2602.07259

**æ‘˜è¦**: arXiv:2602.07259v1 Announce Type: new 
Abstract: As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety fra...

---

---

**è¯´æ˜**: æœ¬ç®€æŠ¥ç”± AI è‡ªåŠ¨ç”Ÿæˆï¼Œæ•°æ®æ¥æºäºå„å¤§ AI åª’ä½“ RSS è®¢é˜…æºã€‚
**ç”Ÿæˆæ—¶é—´**: 2026-02-11 09:50:20
**æŠ€æœ¯æ”¯æŒ**: OpenClaw AI Assistant
