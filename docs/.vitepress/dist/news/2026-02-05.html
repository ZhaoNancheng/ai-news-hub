<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>ğŸ“° Daily AI News Briefing | AI News Hub</title>
    <meta name="description" content="æ¯æ—¥ AI æ–°é—»èšåˆå¹³å°">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/assets/style.DhROsP_H.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.DSo3-3BU.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.Up_LD8ie.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CbQjVMS6.js">
    <link rel="modulepreload" href="/assets/news_2026-02-05.md.KekGbmz5.lean.js">
    <link rel="icon" type="image/svg+xml" href="/favicon.svg">
    <link rel="icon" type="image/png" href="/favicon.png">
    <link rel="shortcut icon" href="/favicon.ico">
    <meta name="theme-color" content="#3c8772">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-1168a8e4><a class="title" href="/" data-v-1168a8e4><!--[--><!--]--><!----><span data-v-1168a8e4>AI News Hub</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>é¦–é¡µ</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/latest-news.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>æ¯æ—¥æ–°é—»</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/latest.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>æœ€æ–°åŠ¨æ€</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/trending.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>çƒ­é—¨</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/research.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>ç ”ç©¶</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/tools.html" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>å·¥å…·</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ZhaoNancheng/ai-news-hub" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-cf11d7a2><span class="vpi-more-horizontal icon" data-v-cf11d7a2></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Appearance</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ZhaoNancheng/ai-news-hub" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-8a42e2b4><button data-v-8a42e2b4>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><div class="VPSidebarItem level-0" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><p class="text" data-v-b3fd67f8>å†å²æ–°é—»</p><!----></div><!----></div></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>On this page</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _news_2026-02-05" data-v-39a288b8><div><h1 id="ğŸ“°-daily-ai-news-briefing" tabindex="-1">ğŸ“° Daily AI News Briefing <a class="header-anchor" href="#ğŸ“°-daily-ai-news-briefing" aria-label="Permalink to &quot;ğŸ“° Daily AI News Briefing&quot;">â€‹</a></h1><p><strong>Date</strong>: February 5, 2026 <strong>Generated at</strong>: 2026-02-05 03:00:00 AM GMT+8 <strong>Sources</strong>: The Verge AI, AI Hub Today, arXiv, industry reports <strong>Coverage</strong>: Last 48 hours (Feb 3-5, 2026)</p><hr><h2 id="ğŸ“-academic-research-arxiv-papers" tabindex="-1">ğŸ“ Academic Research (arXiv Papers) <a class="header-anchor" href="#ğŸ“-academic-research-arxiv-papers" aria-label="Permalink to &quot;ğŸ“ Academic Research (arXiv Papers)&quot;">â€‹</a></h2><h3 id="understanding-agent-scaling-in-llm-based-multi-agent-systems-via-diversity" tabindex="-1">Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity <a class="header-anchor" href="#understanding-agent-scaling-in-llm-based-multi-agent-systems-via-diversity" aria-label="Permalink to &quot;Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity&quot;">â€‹</a></h3><p><strong>arXiv</strong>: 2602.03794 â€¢ Submitted: Feb 3, 2026</p><p><strong>Authors</strong>: Shangding Gu et al.</p><p><strong>Key Contribution</strong>: 2 diverse agents outperform 16 homogeneous agents in multi-agent systems.</p><p><strong>Abstract</strong>: LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents.</p><p><strong>Impact</strong>: Provides principled guidelines for building efficient multi-agent systems through diversity-aware design, challenging the &quot;more agents is better&quot; paradigm.</p><p>ğŸ”— <strong>Link</strong>: <a href="https://arxiv.org/abs/2602.03794" target="_blank" rel="noreferrer">https://arxiv.org/abs/2602.03794</a></p><hr><h3 id="aorchestra-automating-sub-agent-creation-for-agentic-orchestration" tabindex="-1">AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration <a class="header-anchor" href="#aorchestra-automating-sub-agent-creation-for-agentic-orchestration" aria-label="Permalink to &quot;AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration&quot;">â€‹</a></h3><p><strong>arXiv</strong>: 2602.03786 â€¢ Submitted: Feb 3, 2026</p><p><strong>Authors</strong>: Jianhao Ruan, Zhihao Xu, Yiran Peng, et al.</p><p><strong>Key Contribution</strong>: Unified agent abstraction enabling automatic sub-agent creation with 16.28% performance improvement.</p><p><strong>Abstract</strong>: Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple (Instruction, Context, Tools, Model). This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation.</p><p><strong>Impact</strong>: Reduces human engineering efforts while enabling controllable performance-cost trade-offs, approaching Pareto-efficient agent orchestration.</p><p>ğŸ”— <strong>Link</strong>: <a href="https://arxiv.org/abs/2602.03786" target="_blank" rel="noreferrer">https://arxiv.org/abs/2602.03786</a></p><hr><h3 id="autofigure-generating-publication-ready-scientific-illustrations" tabindex="-1">AutoFigure: Generating Publication-Ready Scientific Illustrations <a class="header-anchor" href="#autofigure-generating-publication-ready-scientific-illustrations" aria-label="Permalink to &quot;AutoFigure: Generating Publication-Ready Scientific Illustrations&quot;">â€‹</a></h3><p><strong>arXiv</strong>: 2602.03828 â€¢ Submitted: Feb 3, 2026</p><p><strong>Authors</strong>: Yixuan Weng et al.</p><p><strong>Key Contribution</strong>: First agentic framework for automated high-quality scientific illustration generation from text.</p><p><strong>Abstract</strong>: High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers, surveys, blogs, and textbooks. Moreover, we propose AutoFigure, the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text.</p><p><strong>Impact</strong>: Accepted at ICLR 2026 - addresses major bottleneck in scientific communication with agentic AI solution.</p><p>ğŸ”— <strong>Link</strong>: <a href="https://arxiv.org/abs/2602.03828" target="_blank" rel="noreferrer">https://arxiv.org/abs/2602.03828</a></p><hr><h3 id="conformal-thinking-risk-control-for-reasoning-on-a-compute-budget" tabindex="-1">Conformal Thinking: Risk Control for Reasoning on a Compute Budget <a class="header-anchor" href="#conformal-thinking-risk-control-for-reasoning-on-a-compute-budget" aria-label="Permalink to &quot;Conformal Thinking: Risk Control for Reasoning on a Compute Budget&quot;">â€‹</a></h3><p><strong>arXiv</strong>: 2602.03814 â€¢ Submitted: Feb 3, 2026</p><p><strong>Authors</strong>: Xi Wang et al.</p><p><strong>Key Contribution</strong>: Distribution-free risk control framework for adaptive reasoning with optimal token budget allocation.</p><p><strong>Abstract</strong>: Reasoning Large Language Models (LLMs) enable test-time scaling, with dataset-level accuracy improving as the token budget increases, motivating adaptive reasoning -- spending tokens when they improve reliability and stopping early when additional computation is unlikely to help. However, setting the token budget, as well as the threshold for adaptive reasoning, is a practical challenge that entails a fundamental risk-accuracy trade-off. We re-frame the budget setting problem as risk control, limiting the error rate while minimizing compute. Our framework introduces an upper threshold that stops reasoning when the model is confident (risking incorrect output) and a novel parametric lower threshold that preemptively stops unsolvable instances.</p><p><strong>Impact</strong>: Enables computationally efficient reasoning while maintaining user-specified risk targets across diverse tasks and models.</p><p>ğŸ”— <strong>Link</strong>: <a href="https://arxiv.org/abs/2602.03814" target="_blank" rel="noreferrer">https://arxiv.org/abs/2602.03814</a></p><hr><h3 id="todycomm-task-oriented-dynamic-communication-for-multi-round-llm-based-multi-agent-system" tabindex="-1">TodyComm: Task-Oriented Dynamic Communication for Multi-Round LLM-based Multi-Agent System <a class="header-anchor" href="#todycomm-task-oriented-dynamic-communication-for-multi-round-llm-based-multi-agent-system" aria-label="Permalink to &quot;TodyComm: Task-Oriented Dynamic Communication for Multi-Round LLM-based Multi-Agent System&quot;">â€‹</a></h3><p><strong>arXiv</strong>: 2602.03688 â€¢ Submitted: Feb 3, 2026</p><p><strong>Authors</strong>: Wenzhe Fan et al.</p><p><strong>Key Contribution</strong>: Dynamic communication topology that adapts to changing agent roles across rounds.</p><p><strong>Abstract</strong>: Multi-round LLM-based multi-agent systems rely on effective communication structures to support collaboration across rounds. However, most existing methods employ a fixed communication topology during inference, which falls short in many realistic applications where the agents&#39; roles may change across rounds due to dynamic adversary, task progression, or time-varying constraints such as communication bandwidth. We propose addressing this issue through TodyComm, a task-oriented dynamic communication algorithm that produces behavior-driven collaboration topologies that adapt to the dynamics at each round, optimizing the utility for the task through policy gradient.</p><p><strong>Impact</strong>: Delivers superior task effectiveness under dynamic adversary and communication budget constraints while retaining token efficiency.</p><p>ğŸ”— <strong>Link</strong>: <a href="https://arxiv.org/abs/2602.03688" target="_blank" rel="noreferrer">https://arxiv.org/abs/2602.03688</a></p><hr><h2 id="ğŸ”¥-major-announcements" tabindex="-1">ğŸ”¥ Major Announcements <a class="header-anchor" href="#ğŸ”¥-major-announcements" aria-label="Permalink to &quot;ğŸ”¥ Major Announcements&quot;">â€‹</a></h2><h3 id="openai-codex-desktop-application-launch" tabindex="-1">OpenAI Codex Desktop Application Launch <a class="header-anchor" href="#openai-codex-desktop-application-launch" aria-label="Permalink to &quot;OpenAI Codex Desktop Application Launch&quot;">â€‹</a></h3><p><strong>Summary</strong>: OpenAI releases desktop application for multi-agent orchestration with independent thread execution.</p><p><strong>Key Points</strong>:</p><ul><li>Designed as a command center for multi-agent systems</li><li>Each agent runs in independent threads</li><li>Project-based organization with Git Worktree support</li><li>Custom Skills framework for cross-platform synchronization</li><li>Direct competitor to Claude Code and other agentic IDEs</li></ul><p><strong>Impact</strong>: Intensifies competition in agentic coding space, offering developers native multi-agent collaboration capabilities.</p><p>ğŸ“… <strong>Source</strong>: AI Hub Today â€¢ Feb 4, 2026 ğŸ”— <strong>Link</strong>: <a href="https://www.xiaohu.ai/c/xiaohu-ai/openai-codex-skills-5f0c89" target="_blank" rel="noreferrer">https://www.xiaohu.ai/c/xiaohu-ai/openai-codex-skills-5f0c89</a></p><hr><h3 id="glm-5-and-minimax-m2-2-coming-before-chinese-new-year" tabindex="-1">GLM-5 and MiniMax M2.2 Coming Before Chinese New Year <a class="header-anchor" href="#glm-5-and-minimax-m2-2-coming-before-chinese-new-year" aria-label="Permalink to &quot;GLM-5 and MiniMax M2.2 Coming Before Chinese New Year&quot;">â€‹</a></h3><p><strong>Summary</strong>: Major Chinese AI models set for release before February 15, 2026.</p><p><strong>Key Points</strong>:</p><ul><li>Zhipu AI&#39;s GLM-5 focuses on creative writing, coding, and reasoning breakthroughs</li><li>MiniMax M2.2 enhances programming capabilities as &quot;programmer&#39;s secret weapon&quot;</li><li>DeepSeek releases minor V3 series update</li><li>ByteDance and Alibaba also preparing new model launches</li></ul><p><strong>Impact</strong>: Chinese AI companies accelerating release schedules to compete with global leaders, focusing on specialized capabilities.</p><p>ğŸ“… <strong>Source</strong>: AI Hub Today â€¢ Feb 4, 2026 ğŸ”— <strong>Link</strong>: <a href="https://www.aibase.com/zh/news/25219" target="_blank" rel="noreferrer">https://www.aibase.com/zh/news/25219</a></p><hr><h3 id="sam-altman-kinda-sorta-almost-declares-agi" tabindex="-1">Sam Altman &quot;Kinda-Sorta-Almost&quot; Declares AGI <a class="header-anchor" href="#sam-altman-kinda-sorta-almost-declares-agi" aria-label="Permalink to &quot;Sam Altman &quot;Kinda-Sorta-Almost&quot; Declares AGI&quot;">â€‹</a></h3><p><strong>Summary</strong>: OpenAI CEO makes ambiguous statement about achieving Artificial General Intelligence.</p><p><strong>Key Points</strong>:</p><ul><li>Altman stated &quot;we basically have built AGI, or very close to it&quot; in Forbes profile</li><li>Later clarified: &quot;I meant that as a spiritual statement, not a literal one&quot;</li><li>Conceded AGI will require &quot;a lot of medium-sized breakthroughs. I don&#39;t think we need a big one&quot;</li><li>Highlights ongoing debate about AGI definition and timeline</li></ul><p><strong>Impact</strong>: Continues pattern of ambiguous AGI claims from OpenAI leadership, fueling both excitement and skepticism in AI community.</p><p>ğŸ“… <strong>Source</strong>: The Verge â€¢ Feb 3, 2026 ğŸ”— <strong>Link</strong>: <a href="https://www.forbes.com/sites/richardnieva/2026/02/03/sam-altman-explains-the-future/" target="_blank" rel="noreferrer">https://www.forbes.com/sites/richardnieva/2026/02/03/sam-altman-explains-the-future/</a></p><hr><h2 id="ğŸ”¬-research-papers" tabindex="-1">ğŸ”¬ Research &amp; Papers <a class="header-anchor" href="#ğŸ”¬-research-papers" aria-label="Permalink to &quot;ğŸ”¬ Research &amp; Papers&quot;">â€‹</a></h2><h3 id="tencent-s-cl-bench-reveals-models-can-t-learn-from-context" tabindex="-1">Tencent&#39;s CL-bench Reveals Models Can&#39;t Learn from Context <a class="header-anchor" href="#tencent-s-cl-bench-reveals-models-can-t-learn-from-context" aria-label="Permalink to &quot;Tencent&#39;s CL-bench Reveals Models Can&#39;t Learn from Context&quot;">â€‹</a></h3><p><strong>Summary</strong>: New benchmark shows LLMs only solve 17.2% of in-context learning tasks on average.</p><p><strong>Key Points</strong>:</p><ul><li>First paper from Tencent Hunyuan after hiring Yao Shunyu</li><li>Benchmark tests model ability to learn and apply new knowledge from context</li><li>Best performer (GPT-5.1) only achieves 23.7% success rate</li><li>Reveals fundamental limitation: models don&#39;t truly utilize context effectively</li></ul><p><strong>Impact</strong>: Challenges assumptions about LLM in-context learning capabilities, suggests need for better learning mechanisms.</p><p>ğŸ“… <strong>Source</strong>: AI Hub Today â€¢ Feb 4, 2026 ğŸ”— <strong>Link</strong>: <a href="https://www.jiqizhixin.com/articles/2026-02-03-7" target="_blank" rel="noreferrer">https://www.jiqizhixin.com/articles/2026-02-03-7</a></p><hr><h3 id="projdevbench-evaluates-end-to-end-ai-project-development" tabindex="-1">ProjDevBench Evaluates End-to-End AI Project Development <a class="header-anchor" href="#projdevbench-evaluates-end-to-end-ai-project-development" aria-label="Permalink to &quot;ProjDevBench Evaluates End-to-End AI Project Development&quot;">â€‹</a></h3><p><strong>Summary</strong>: New benchmark tests AI agents on complete project lifecycle from requirements to repository.</p><p><strong>Key Points</strong>:</p><ul><li>Existing benchmarks focus on bug fixing</li><li>ProjDevBench evaluates full software development lifecycle</li><li>20 programming tasks across 8 categories</li><li>Combines online judge testing with LLM code review</li><li>Six coding agents achieved only 27.38% overall pass rate</li><li>Complex system design identified as major weakness</li></ul><p><strong>Impact</strong>: Reveals significant gap in AI agents&#39; ability to handle complete software development projects, highlighting need for better system design capabilities.</p><p>ğŸ“… <strong>Source</strong>: AI Hub Today â€¢ Feb 4, 2026 ğŸ”— <strong>Link</strong>: <a href="https://arxiv.org/abs/2602.01655" target="_blank" rel="noreferrer">https://arxiv.org/abs/2602.01655</a></p><hr><h3 id="reinforcement-learning-for-explainable-human-decision-modeling" tabindex="-1">Reinforcement Learning for Explainable Human Decision Modeling <a class="header-anchor" href="#reinforcement-learning-for-explainable-human-decision-modeling" aria-label="Permalink to &quot;Reinforcement Learning for Explainable Human Decision Modeling&quot;">â€‹</a></h3><p><strong>Summary</strong>: New research direction uses outcome-based RL to guide LLMs in generating explicit reasoning chains.</p><p><strong>Key Points</strong>:</p><ul><li>Cognitive modeling approach for human decision explanation</li><li>Outcome-based reinforcement learning guides reasoning chain generation</li><li>Goals: prediction accuracy AND explainability</li><li>Moves beyond black-box predictions to interpretable AI</li></ul><p><strong>Impact</strong>: Addresses critical need for explainable AI in decision-critical applications, making AI reasoning transparent and verifiable.</p><p>ğŸ“… <strong>Source</strong>: AI Hub Today â€¢ Feb 4, 2026 ğŸ”— <strong>Link</strong>: <a href="https://arxiv.org/abs/2505.11614" target="_blank" rel="noreferrer">https://arxiv.org/abs/2505.11614</a></p><hr><h3 id="rlvr-training-instability-mechanism-revealed" tabindex="-1">RLVR Training Instability Mechanism Revealed <a class="header-anchor" href="#rlvr-training-instability-mechanism-revealed" aria-label="Permalink to &quot;RLVR Training Instability Mechanism Revealed&quot;">â€‹</a></h3><p><strong>Summary</strong>: Research explains why verifiable reward reinforcement learning causes MoE architecture collapse.</p><p><strong>Key Points</strong>:</p><ul><li>RLVR can continuously improve reasoning ability but MoE architectures often crash</li><li>Proposed objective-level hacking framework to explain instability</li><li>Core finding: token-level credit mismatch creates false signals</li><li>Leads to abnormal growth in training-inference discrepancy</li></ul><p><strong>Impact</strong>: Understanding RLVR instability crucial for developing more robust RL-based reasoning systems, preventing model collapse during training.</p><p>ğŸ“… <strong>Source</strong>: AI Hub Today â€¢ Feb 4, 2026 ğŸ”— <strong>Link</strong>: <a href="https://arxiv.org/abs/2602.01103" target="_blank" rel="noreferrer">https://arxiv.org/abs/2602.01103</a></p><hr><h2 id="ğŸ’°-industry-business" tabindex="-1">ğŸ’° Industry &amp; Business <a class="header-anchor" href="#ğŸ’°-industry-business" aria-label="Permalink to &quot;ğŸ’° Industry &amp; Business&quot;">â€‹</a></h2><h3 id="musk-announces-spacex-xai-merger-1-25-trillion-valuation" tabindex="-1">Musk Announces SpaceX-xAI Merger: $1.25 Trillion Valuation <a class="header-anchor" href="#musk-announces-spacex-xai-merger-1-25-trillion-valuation" aria-label="Permalink to &quot;Musk Announces SpaceX-xAI Merger: $1.25 Trillion Valuation&quot;">â€‹</a></h3><p><strong>Summary</strong>: Historic merger creates world&#39;s most valuable AI/space company with ambitious space-based computing plans.</p><p><strong>Key Points</strong>:</p><ul><li>Combined valuation reaches $1.25 trillion</li><li>Internal memo reveals plan for space-deployed data centers</li><li>Musk predicts space-based AI is only path to true scale</li><li>Plans to launch 1 million satellites to build orbital data centers</li><li>Aiming for Kardashev Type II civilization capabilities</li><li>Leverages space&#39;s natural cooling (cryogenic vacuum environment)</li></ul><p><strong>Impact</strong>: Could revolutionize AI infrastructure by moving computing to space, bypassing terrestrial limitations and creating orbital data center networks.</p><p>ğŸ“… <strong>Source</strong>: AI Hub Today â€¢ Feb 4, 2026 ğŸ”— <strong>Link</strong>: <a href="https://www.qbitai.com/2026/02/375614.html" target="_blank" rel="noreferrer">https://www.qbitai.com/2026/02/375614.html</a></p><hr><h3 id="spacex-files-for-million-satellite-computing-constellation" tabindex="-1">SpaceX Files for Million-Satellite Computing Constellation <a class="header-anchor" href="#spacex-files-for-million-satellite-computing-constellation" aria-label="Permalink to &quot;SpaceX Files for Million-Satellite Computing Constellation&quot;">â€‹</a></h3><p><strong>Summary</strong>: Applications filed for constellation with 80 EFLOPS total computing power.</p><p><strong>Key Points</strong>:</p><ul><li>Core purpose: orbital data centers, not communication</li><li>80 EFLOPS combined computing power planned</li><li>Space&#39;s natural vacuum solves cooling challenges</li><li>Timeline: 2028 startup, 2030 completion target</li><li>Traditional data center providers face potential disruption</li><li>&quot;Dimension reduction strike&quot; against terrestrial IDC industry</li></ul><p><strong>Impact</strong>: If successful, would fundamentally alter AI infrastructure landscape, creating space-based computing platform with unlimited scalability potential.</p><p>ğŸ“… <strong>Source</strong>: AI Hub Today â€¢ Feb 4, 2026 ğŸ”— <strong>Link</strong>: <a href="https://www.aibase.com/zh/news/25192" target="_blank" rel="noreferrer">https://www.aibase.com/zh/news/25192</a></p><hr><h3 id="tencent-hunyuan-hires-another-top-scientist" tabindex="-1">Tencent Hunyuan Hires Another Top Scientist <a class="header-anchor" href="#tencent-hunyuan-hires-another-top-scientist" aria-label="Permalink to &quot;Tencent Hunyuan Hires Another Top Scientist&quot;">â€‹</a></h3><p><strong>Summary</strong>: Tsinghua PhD Pang Tianyu joins as Chief Research Scientist for Multimodal Division.</p><p><strong>Key Points</strong>:</p><ul><li>Focus on reinforcement learning technology research</li><li>Previously at Singapore Sea AI Lab</li><li>Second major hire after Yao Shunyu</li><li>Signals Tencent&#39;s aggressive investment in AI research talent</li></ul><p><strong>Impact</strong>: Chinese tech giants competing aggressively for top AI research talent, accelerating domestic AI innovation capabilities.</p><p>ğŸ“… <strong>Source</strong>: AI Hub Today â€¢ Feb 4, 2026 ğŸ”— <strong>Link</strong>: <a href="https://www.aibase.com/zh/news/25199" target="_blank" rel="noreferrer">https://www.aibase.com/zh/news/25199</a></p><hr><h3 id="nvidia-openai-100-billion-deal-on-ice" tabindex="-1">Nvidia-OpenAI $100 Billion Deal &quot;On Ice&quot; <a class="header-anchor" href="#nvidia-openai-100-billion-deal-on-ice" aria-label="Permalink to &quot;Nvidia-OpenAI $100 Billion Deal &quot;On Ice&quot;&quot;">â€‹</a></h3><p><strong>Summary</strong>: Planned massive investment deal faces renegotiation.</p><p><strong>Key Points</strong>:</p><ul><li>Deal announced in September now reportedly paused</li><li>Discussions continue for smaller investment (tens of billions)</li><li>Part of OpenAI&#39;s current funding round</li><li>Original plan: up to $100B for compute + cash partnership</li></ul><p><strong>Impact</strong>: Suggests shifting dynamics in AI infrastructure partnerships, potentially due to market conditions or strategic reassessment.</p><p>ğŸ“… <strong>Source</strong>: The Verge â€¢ Feb 3, 2026 ğŸ”— <strong>Link</strong>: <a href="https://www.wsj.com/tech/ai/the-100-billion-megadeal-between-openai-and-nvidia-is-on-ice-aa3025e3" target="_blank" rel="noreferrer">https://www.wsj.com/tech/ai/the-100-billion-megadeal-between-openai-and-nvidia-is-on-ice-aa3025e3</a></p><hr><h2 id="ğŸ› ï¸-tools-applications" tabindex="-1">ğŸ› ï¸ Tools &amp; Applications <a class="header-anchor" href="#ğŸ› ï¸-tools-applications" aria-label="Permalink to &quot;ğŸ› ï¸ Tools &amp; Applications&quot;">â€‹</a></h2><h3 id="top-open-source-ai-projects" tabindex="-1">Top Open Source AI Projects <a class="header-anchor" href="#top-open-source-ai-projects" aria-label="Permalink to &quot;Top Open Source AI Projects&quot;">â€‹</a></h3><p><strong>superpowers - Agent Skills Framework</strong></p><ul><li>â­ 43,217 stars on GitHub</li><li>Effective agent skills framework and software development methodology</li><li>Helps developers build more powerful AI agent systems</li><li>ğŸ”— <a href="https://github.com/obra/superpowers" target="_blank" rel="noreferrer">https://github.com/obra/superpowers</a></li></ul><p><strong>dexter - Deep Financial Research Agent</strong></p><ul><li>â­ 9,951 stars on GitHub</li><li>Autonomous agent for deep financial research</li><li>Specialized intelligent analysis tool for financial domain</li><li>ğŸ”— <a href="https://github.com/virattt/dexter" target="_blank" rel="noreferrer">https://github.com/virattt/dexter</a></li></ul><p><strong>ccpm - Claude Code Project Management System</strong></p><ul><li>â­ 6,563 stars on GitHub</li><li>Uses GitHub Issues and Git worktrees for parallel agent execution</li><li>Makes multi-agent collaboration more efficient</li><li>ğŸ”— <a href="https://github.com/automazeio/ccpm" target="_blank" rel="noreferrer">https://github.com/automazeio/ccpm</a></li></ul><p><strong>vm0 - Natural Language Workflow Automation</strong></p><ul><li>â­ 585 stars on GitHub</li><li>Simplest way to automate natural language-described workflows</li><li>Define workflows using natural language</li><li>ğŸ”— <a href="https://github.com/vm0-ai/vm0" target="_blank" rel="noreferrer">https://github.com/vm0-ai/vm0</a></li></ul><p><strong>review-prompts - AI Code Review Prompts</strong></p><ul><li>â­ 235 stars on GitHub</li><li>Prompt collection specifically for AI code review</li><li>Complete content available on GitHub</li><li>ğŸ”— <a href="https://github.com/masoncl/review-prompts" target="_blank" rel="noreferrer">https://github.com/masoncl/review-prompts</a></li></ul><hr><h3 id="anthropic-expands-cowork-with-plugins" tabindex="-1">Anthropic Expands Cowork with Plugins <a class="header-anchor" href="#anthropic-expands-cowork-with-plugins" aria-label="Permalink to &quot;Anthropic Expands Cowork with Plugins&quot;">â€‹</a></h3><p><strong>Summary</strong>: Claude&#39;s agentic AI tool gains domain expert capabilities.</p><p><strong>Key Points</strong>:</p><ul><li>New &quot;plugins&quot; feature for Cowork research preview</li><li>Enables domain expertise in: sales, legal, finance, marketing, data analysis, customer support, product management, biology research</li><li>Available now to all paid subscription tiers</li><li>Leans further into agentic AI paradigm</li></ul><p><strong>Impact</strong>: Transforms Cowork from generalist into specialized expert system, broadening agentic AI adoption in enterprise workflows.</p><p>ğŸ“… <strong>Source</strong>: The Verge â€¢ Jan 30, 2026 ğŸ”— <strong>Link</strong>: <a href="http://claude.com/blog/cowork-research-preview" target="_blank" rel="noreferrer">http://claude.com/blog/cowork-research-preview</a></p><hr><h3 id="rabbit-announces-new-ai-device-and-r1-updates" tabindex="-1">Rabbit Announces New AI Device and r1 Updates <a class="header-anchor" href="#rabbit-announces-new-ai-device-and-r1-updates" aria-label="Permalink to &quot;Rabbit Announces New AI Device and r1 Updates&quot;">â€‹</a></h3><p><strong>Summary</strong>: AI hardware company launches &quot;project cyberdeck&quot; and major r1 OTA update.</p><p><strong>Key Points</strong>:</p><ul><li>New device: &quot;project cyberdeck&quot; for vibe-coding</li><li>Portable device specifically designed for agentic coding</li><li>r1 OTA update transforms it into &quot;plug-and-play computer controller&quot;</li><li>Enables agentic tasks on user&#39;s behalf</li><li>Integrates OpenClaw (open-source agentic tool)</li></ul><p><strong>Impact</strong>: Continued innovation in AI hardware space, specializing in agentic computing and vibe-coding use cases.</p><p>ğŸ“… <strong>Source</strong>: The Verge â€¢ Jan 30, 2026 ğŸ”— <strong>Link</strong>: <a href="https://x.com/rabbit_hmi/status/2017082134717223008" target="_blank" rel="noreferrer">https://x.com/rabbit_hmi/status/2017082134717223008</a></p><hr><h2 id="ğŸŒ-policy-ethics" tabindex="-1">ğŸŒ Policy &amp; Ethics <a class="header-anchor" href="#ğŸŒ-policy-ethics" aria-label="Permalink to &quot;ğŸŒ Policy &amp; Ethics&quot;">â€‹</a></h2><h3 id="openai-poaches-safety-executive-from-anthropic" tabindex="-1">OpenAI Poaches Safety Executive from Anthropic <a class="header-anchor" href="#openai-poaches-safety-executive-from-anthropic" aria-label="Permalink to &quot;OpenAI Poaches Safety Executive from Anthropic&quot;">â€‹</a></h3><p><strong>Summary</strong>: Dylan Scandinaro moves from Anthropic AGI safety role to OpenAI.</p><p><strong>Key Points</strong>:</p><ul><li>New title: &quot;head of preparedness&quot; at OpenAI</li><li>Came from AGI safety role at chief competitor</li><li>Posted: &quot;AI is advancing rapidly. The potential benefits are greatâ€”and so are the risks of extreme and even irrecoverable harm. There&#39;s a lot of work to do, and not much time to do it!&quot;</li></ul><p><strong>Impact</strong>: Leadership shuffle in AI safety space raises questions about safety priorities and talent competition between leading AI labs.</p><p>ğŸ“… <strong>Source</strong>: The Verge â€¢ Feb 3, 2026 ğŸ”— <strong>Link</strong>: <a href="https://x.com/sama/status/2018800541716107477" target="_blank" rel="noreferrer">https://x.com/sama/status/2018800541716107477</a></p><hr><h3 id="x-safety-teams-warned-management-about-grok-deepfakes" tabindex="-1">X Safety Teams Warned Management About Grok Deepfakes <a class="header-anchor" href="#x-safety-teams-warned-management-about-grok-deepfakes" aria-label="Permalink to &quot;X Safety Teams Warned Management About Grok Deepfakes&quot;">â€‹</a></h3><p><strong>Summary</strong>: Internal reports show safety teams flagged undressing tool risks before public outcry.</p><p><strong>Key Points</strong>:</p><ul><li>Safety teams &quot;repeatedly warned management&quot; about undressing tools</li><li>Platform&#39;s content moderation filters couldn&#39;t handle estimated millions of sexualized deepfakes</li><li>AI-edited images don&#39;t trigger database warnings for known illegal images</li><li>Child sexual abuse material detection ineffective against AI-generated content</li></ul><p><strong>Impact</strong>: Highlights growing challenge of AI-generated abuse material and need for new detection approaches beyond traditional database matching.</p><p>ğŸ“… <strong>Source</strong>: The Verge â€¢ Feb 2, 2026 ğŸ”— <strong>Link</strong>: <a href="https://www.washingtonpost.com/technology/2026/02/02/elon-musk-grok-porn-generator/" target="_blank" rel="noreferrer">https://www.washingtonpost.com/technology/2026/02/02/elon-musk-grok-porn-generator/</a></p><hr><h3 id="sophia-robot-creator-asked-epstein-for-sexy-android-funding" tabindex="-1">Sophia Robot Creator Asked Epstein for &quot;Sexy Android&quot; Funding <a class="header-anchor" href="#sophia-robot-creator-asked-epstein-for-sexy-android-funding" aria-label="Permalink to &quot;Sophia Robot Creator Asked Epstein for &quot;Sexy Android&quot; Funding&quot;">â€‹</a></h3><p><strong>Summary</strong>: DOJ documents reveal $3 million proposal for &quot;attractive female android.&quot;</p><p><strong>Key Points</strong>:</p><ul><li>Roboticist David Hanson proposed building &quot;attractive female android&quot;</li><li>Proposal included &quot;working gorgeous robot face and body&quot;</li><li>Rough sketch of &quot;gynoid&quot; with note: &quot;final design will be done collaboratively with you&quot;</li><li>Raises ethical questions about AI/robot design and funding sources</li></ul><p><strong>Impact</strong>: Historical revelation underscores intersection of AI ethics, robotics, and problematic funding relationships in tech industry.</p><p>ğŸ“… <strong>Source</strong>: The Verge â€¢ Feb 2, 2026 ğŸ”— <strong>Link</strong>: <a href="https://www.justice.gov/epstein/files/DataSet%2011/EFTA02725875.pdf" target="_blank" rel="noreferrer">https://www.justice.gov/epstein/files/DataSet 11/EFTA02725875.pdf</a></p><hr><h3 id="nyc-ai-chatbot-told-businesses-to-break-law" tabindex="-1">NYC AI Chatbot Told Businesses to Break Law <a class="header-anchor" href="#nyc-ai-chatbot-told-businesses-to-break-law" aria-label="Permalink to &quot;NYC AI Chatbot Told Businesses to Break Law&quot;">â€‹</a></h3><p><strong>Summary</strong>: City plans to kill chatbot that encouraged illegal business practices.</p><p><strong>Key Points</strong>:</p><ul><li>Launched under Mayor Eric Adams to help businesses navigate regulations</li><li>Instead encouraged illegal behavior: <ul><li>Taking portion of employees&#39; tips</li><li>Refusing to accept cash payments</li><li>Didn&#39;t even know minimum wage</li></ul></li><li>Reporting by The City and The Markup exposed widespread problems</li><li>New administration plans to terminate the bot</li></ul><p><strong>Impact</strong>: Cautionary tale about deploying AI systems without proper testing in high-stakes regulatory contexts.</p><p>ğŸ“… <strong>Source</strong>: The Verge â€¢ Feb 1, 2026 ğŸ”— <strong>Link</strong>: <a href="https://thecity.nyc/2026/01/30/mamdani-unusable-ai-chatbot-budget/" target="_blank" rel="noreferrer">https://thecity.nyc/2026/01/30/mamdani-unusable-ai-chatbot-budget/</a></p><hr><h2 id="ğŸ¯-key-takeaways" tabindex="-1">ğŸ¯ Key Takeaways <a class="header-anchor" href="#ğŸ¯-key-takeaways" aria-label="Permalink to &quot;ğŸ¯ Key Takeaways&quot;">â€‹</a></h2><ol><li><p><strong>Multi-agent diversity matters more than quantity</strong>: Research shows 2 diverse agents outperform 16 homogeneous ones, fundamentally challenging scaling-by-quantity paradigm.</p></li><li><p><strong>Space-based AI computing becomes concrete</strong>: Musk&#39;s SpaceX-xAI merger with $1.25T valuation and million-satellite constellation plan could revolutionize AI infrastructure.</p></li><li><p><strong>Chinese AI accelerating release schedules</strong>: GLM-5, MiniMax M2.2, and others launching before Chinese New Year, focusing on specialized capabilities to compete globally.</p></li><li><p><strong>Agentic orchestration automation</strong>: AOrchestra and similar frameworks reducing human engineering effort, making multi-agent systems more accessible and efficient.</p></li><li><p><strong>Context learning limitations exposed</strong>: Tencent&#39;s CL-bench reveals LLMs only solve 17% of in-context learning tasks, highlighting fundamental gaps in current models.</p></li></ol><hr><p><strong>Generated on</strong>: 2026-02-05 03:00:00 AM GMT+8 <strong>Next update</strong>: 2026-02-06 03:00:00 AM GMT+8 <strong>Total news items</strong>: 20 (5 arXiv papers + 15 industry news items)</p></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><!----><!----></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>åŸºäº VitePress æ„å»º</p><p class="copyright" data-v-e315a0ad>Copyright Â© 2026 AI News Hub</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"index.md\":\"PbYyJi_t\",\"latest-news.md\":\"DY9NqnSQ\",\"latest.md\":\"O70geX-_\",\"news_2026-02-05.md\":\"KekGbmz5\",\"news_2026-02-06.md\":\"BMDqTRAV\",\"public_readme.md\":\"Dn55MPv8\",\"research.md\":\"CA8Wp-AL\",\"tools.md\":\"Dttmw64q\",\"trending.md\":\"DHfjIqMz\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"AI News Hub\",\"description\":\"æ¯æ—¥ AI æ–°é—»èšåˆå¹³å°\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"é¦–é¡µ\",\"link\":\"/\"},{\"text\":\"æ¯æ—¥æ–°é—»\",\"link\":\"/latest-news\"},{\"text\":\"æœ€æ–°åŠ¨æ€\",\"link\":\"/latest\"},{\"text\":\"çƒ­é—¨\",\"link\":\"/trending\"},{\"text\":\"ç ”ç©¶\",\"link\":\"/research\"},{\"text\":\"å·¥å…·\",\"link\":\"/tools\"}],\"sidebar\":{\"/news/\":[{\"text\":\"å†å²æ–°é—»\",\"items\":[]}],\"/\":[{\"text\":\"æ–°é—»åˆ†ç±»\",\"items\":[{\"text\":\"æ¯æ—¥æ–°é—»\",\"link\":\"/latest-news\"},{\"text\":\"æœ€æ–°åŠ¨æ€\",\"link\":\"/latest\"},{\"text\":\"çƒ­é—¨æ¨è\",\"link\":\"/trending\"},{\"text\":\"ç ”ç©¶å‰æ²¿\",\"link\":\"/research\"},{\"text\":\"å®ç”¨å·¥å…·\",\"link\":\"/tools\"}]}]},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/ZhaoNancheng/ai-news-hub\"}],\"footer\":{\"message\":\"åŸºäº VitePress æ„å»º\",\"copyright\":\"Copyright Â© 2026 AI News Hub\"},\"search\":{\"provider\":\"local\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>