#!/usr/bin/env python3
"""
å†…å®¹åˆ†ç±»å’Œæ ‡ç­¾ç³»ç»Ÿ
æ ¹æ®å…³é”®è¯è‡ªåŠ¨åˆ†é…ç±»åˆ«å’Œæ ‡ç­¾
"""

import re
from typing import List, Dict, Tuple

# AI ä¸»é¢˜åˆ†ç±»å®šä¹‰
TOPIC_CATEGORIES = {
    'ğŸ¤– å¤§æ¨¡å‹ & åŸºç¡€æ¨¡å‹': [
        'gpt', 'claude', 'gemini', 'llm', 'large language model',
        'foundation model', 'transformer', 'bert', 'diffusion',
        'stable diffusion', 'midjourney', 'dall-e'
    ],
    'ğŸ¤¬ æ™ºèƒ½ä½“ & å¤šæ™ºèƒ½ä½“': [
        'agent', 'multi-agent', 'autonomous', 'robotics',
        'embodied ai', 'orchestration', 'agentic'
    ],
    'ğŸ¯ ä¼ä¸š & å•†ä¸šåº”ç”¨': [
        'startup', 'funding', 'investment', 'acquisition',
        'ipo', 'venture capital', 'enterprise', 'business',
        'company', 'launch', 'product', 'service'
    ],
    'ğŸ”¬ ç ”ç©¶ & è®ºæ–‡': [
        'paper', 'research', 'arxiv', 'study', 'experiment',
        'breakthrough', 'algorithm', 'methodology', 'benchmark',
        'conference', 'neurips', 'icml', 'iclr'
    ],
    'ğŸ’» å¼€å‘å·¥å…· & æ¡†æ¶': [
        'framework', 'library', 'api', 'sdk', 'tool',
        'platform', 'github', 'open source', 'repository',
        'code', 'programming', 'deployment'
    ],
    'ğŸ¨ ç”Ÿæˆå¼ AI & åˆ›æ„': [
        'generative', 'creative', 'art', 'design', 'image',
        'video', 'audio', 'music', 'content creation',
        'creative ai', 'design tool'
    ],
    'ğŸŒ æœç´¢ & ä¿¡æ¯æ£€ç´¢': [
        'search', 'retrieval', 'rag', 'embedding',
        'vector database', 'semantic search', 'information',
        'query', 'indexing'
    ],
    'ğŸ§  æ¨ç† & è®¤çŸ¥': [
        'reasoning', 'thinking', 'planning', 'logic',
        'inference', 'chain of thought', 'cognitive',
        'decision making', 'problem solving'
    ],
    'ğŸ’¬ å¯¹è¯ & äº¤äº’': [
        'chatbot', 'conversational', 'dialogue', 'voice',
        'nlp', 'natural language', 'understanding',
        'interaction', 'user interface'
    ],
    'ğŸ›¡ï¸ å®‰å…¨ & ä¼¦ç†': [
        'safety', 'ethics', 'bias', 'fairness',
        'privacy', 'security', 'regulation', 'policy',
        'alignment', 'responsible ai'
    ]
}

# å…¬å¸/äº§å“æ ‡ç­¾
COMPANY_TAGS = {
    'openai': ['openai', 'gpt', 'chatgpt', 'dall-e', 'sora'],
    'google': ['google', 'gemini', 'bard', 'deepmind'],
    'anthropic': ['anthropic', 'claude'],
    'meta': ['meta', 'facebook', 'llama'],
    'microsoft': ['microsoft', 'copilot', 'azure'],
    'amazon': ['amazon', 'aws', 'bedrock'],
    'nvidia': ['nvidia', 'gpu', 'cuda'],
    'apple': ['apple', 'siri'],
    'tesla': ['tesla', 'spacex', 'elon musk', 'xai'],
}

def classify_content(title: str, description: str = '') -> Tuple[List[str], List[str]]:
    """
    åˆ†ç±»å†…å®¹å¹¶è¿”å›æ ‡ç­¾
    
    è¿”å›: (åˆ†ç±»åˆ—è¡¨, æ ‡ç­¾åˆ—è¡¨)
    """
    text = f"{title} {description}".lower()
    
    # 1. ä¸»é¢˜åˆ†ç±»
    matched_categories = []
    for category, keywords in TOPIC_CATEGORIES.items():
        if any(keyword in text for keyword in keywords):
            matched_categories.append(category)
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»
    if not matched_categories:
        matched_categories = ['ğŸ“° ç»¼åˆ AI èµ„è®¯']
    
    # 2. å…¬å¸/äº§å“æ ‡ç­¾
    matched_companies = []
    for company, keywords in COMPANY_TAGS.items():
        if any(keyword in text for keyword in keywords):
            matched_companies.append(f"@{company}")
    
    # 3. æŠ€æœ¯æ ‡ç­¾
    tech_tags = []
    
    # æ¨¡å‹ç±»å‹
    if any(word in text for word in ['gpt-4', 'gpt4', 'gpt 4']):
        tech_tags.append('#GPT-4')
    if any(word in text for word in ['claude', 'anthropic']):
        tech_tags.append('#Claude')
    if any(word in text for word in ['gemini', 'google']):
        tech_tags.append('#Gemini')
    if any(word in text for word in ['llama', 'meta']):
        tech_tags.append('#LLaMA')
    
    # æŠ€æœ¯æ–¹å‘
    if any(word in text for word in ['multimodal', 'multi-modal']):
        tech_tags.append('#å¤šæ¨¡æ€')
    if any(word in text for word in ['rag', 'retrieval']):
        tech_tags.append('#RAG')
    if any(word in text for word in ['agent', 'autonomous']):
        tech_tags.append('#AIæ™ºèƒ½ä½“')
    if any(word in text for word in ['vision', 'image', 'video']):
        tech_tags.append('#è®¡ç®—æœºè§†è§‰')
    
    return matched_categories, matched_companies + tech_tags

def calculate_priority_score(title: str, description: str, source: str, 
                          recency_hours: int = 24) -> float:
    """
    è®¡ç®—å†…å®¹ä¼˜å…ˆçº§è¯„åˆ†
    
    è¯„åˆ†æ ‡å‡†ï¼š
    - æ—¶æ•ˆæ€§ï¼ˆ0-30åˆ†ï¼‰ï¼šè¶Šæ–°è¶Šé«˜
    - æ¥æºè´¨é‡ï¼ˆ0-30åˆ†ï¼‰ï¼šarXiv/å®˜æ–¹åšå®¢ > å¤§åª’ä½“ > ç¤¾äº¤
    - å†…å®¹å®Œæ•´æ€§ï¼ˆ0-20åˆ†ï¼‰ï¼šæœ‰æ‘˜è¦ > åªæœ‰æ ‡é¢˜
    - ç›¸å…³æ€§ï¼ˆ0-20åˆ†ï¼‰ï¼šç›´æ¥ AI ç›¸å…³ > é—´æ¥ç›¸å…³
    """
    score = 0.0
    text = f"{title} {description}".lower()
    
    # 1. æ—¶æ•ˆæ€§ï¼ˆ0-30åˆ†ï¼‰
    if recency_hours <= 6:
        score += 30
    elif recency_hours <= 12:
        score += 25
    elif recency_hours <= 24:
        score += 20
    elif recency_hours <= 48:
        score += 10
    else:
        score += 5
    
    # 2. æ¥æºè´¨é‡ï¼ˆ0-30åˆ†ï¼‰
    high_quality = ['arxiv', 'mit technology review', 'nature', 'science']
    medium_quality = ['techcrunch', 'venturebeat', 'the verge', 'wired']
    
    if any(q in source.lower() for q in high_quality):
        score += 30
    elif any(q in source.lower() for q in medium_quality):
        score += 25
    elif 'hacker news' in source.lower():
        score += 20  # è´¨é‡è¿‡æ»¤å
    elif 'github' in source.lower():
        score += 15
    else:
        score += 10
    
    # 3. å†…å®¹å®Œæ•´æ€§ï¼ˆ0-20åˆ†ï¼‰
    if description and len(description) > 100:
        score += 20
    elif description:
        score += 10
    else:
        score += 5
    
    # 4. ç›¸å…³æ€§ï¼ˆ0-20åˆ†ï¼‰
    ai_keywords = ['gpt', 'llm', 'agent', 'machine learning', 'deep learning']
    if any(keyword in text for keyword in ai_keywords):
        score += 20
    elif any(word in text for word in ['ai', 'artificial intelligence', 'automation']):
        score += 15
    elif any(word in text for word in ['tech', 'startup', 'funding']):
        score += 8
    else:
        score += 3
    
    return score

def generate_summary(articles: List[Dict], top_n: int = 5) -> str:
    """
    ç”Ÿæˆæ¯æ—¥çƒ­ç‚¹æ€»ç»“
    """
    # æŒ‰ä¼˜å…ˆçº§æ’åº
    scored_articles = []
    for article in articles:
        title = article.get('title', '')
        description = article.get('description', '')
        source = article.get('source', '')
        
        score = calculate_priority_score(title, description, source)
        scored_articles.append({
            'article': article,
            'score': score
        })
    
    # é€‰æ‹© top N
    top_articles = sorted(scored_articles, key=lambda x: x['score'], reverse=True)[:top_n]
    
    # æå–å…³é”®ä¸»é¢˜
    all_tags = []
    for item in top_articles:
        title = item['article'].get('title', '')
        description = item['article'].get('description', '')
        categories, tags = classify_content(title, description)
        all_tags.extend(categories)
    
    # ç»Ÿè®¡æœ€å¸¸è§ä¸»é¢˜
    from collections import Counter
    top_topics = [tag for tag, count in Counter(all_tags).most_common(5)]
    
    # ç”Ÿæˆæ€»ç»“
    summary = f"""## ğŸ”¥ ä»Šæ—¥çƒ­ç‚¹æ€»ç»“

**æœ€çƒ­é—¨ä¸»é¢˜ï¼š** {' â€¢ '.join(top_topics[:3])}

**ä»Šæ—¥ {top_n} å¤§äº‹ä»¶ï¼š**

"""
    
    for i, item in enumerate(top_articles, 1):
        article = item['article']
        title = article.get('title', '')
        source = article.get('source', '')
        score = item['score']
        
        summary += f"""### {i}. {title}
**æ¥æºï¼š** {source} â€¢ **ä¼˜å…ˆçº§ï¼š** {score:.1f}/100

"""
    
    return summary

if __name__ == '__main__':
    # æµ‹è¯•
    test_articles = [
        {
            'title': 'OpenAI GPT-5 Announced with Revolutionary Reasoning',
            'description': 'OpenAI today announced GPT-5, featuring breakthrough reasoning capabilities...',
            'source': 'TechCrunch AI'
        },
        {
            'title': 'New Multi-Agent System Achieves Human-Level Performance',
            'description': 'Researchers from Stanford and MIT developed a multi-agent system...',
            'source': 'arXiv'
        }
    ]
    
    for article in test_articles:
        categories, tags = classify_content(
            article['title'],
            article.get('description', '')
        )
        score = calculate_priority_score(
            article['title'],
            article.get('description', ''),
            article['source']
        )
        
        print(f"\næ ‡é¢˜ï¼š{article['title']}")
        print(f"åˆ†ç±»ï¼š{', '.join(categories)}")
        print(f"æ ‡ç­¾ï¼š{', '.join(tags)}")
        print(f"è¯„åˆ†ï¼š{score:.1f}/100")
